{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index\n",
    "<ol>\n",
    "    <li>Chapter 1</li>\n",
    "    <li>Chapter 2</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Chapter 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>PyTorch - python based computational graph framework for deep learning algorithm inplementation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Supervised Learning Paradigm</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observations:\n",
    "    items we want to make predictions about (denoted as \"x\" referred to as inputs)\n",
    "- Targets:\n",
    "    labels corresponding to an observation\n",
    "    what we're predicting\n",
    "    denoted as y\n",
    "    often called ground truth\n",
    "- Model:\n",
    "    mathematical expression/function\n",
    "    takes value x (observation) tries to predict y (target)\n",
    "- Parameters:\n",
    "    often reffered to as weights\n",
    "    parametrize the Model\n",
    "    w or w with a hat is normally used to to denote it\n",
    "- Predictions:\n",
    "    often referred to as estimates\n",
    "    value predicted by model\n",
    "    usually denoted as y with a hat\n",
    "- Loss function:\n",
    "    compares y hat (predictions) with y (ground truth/targets)\n",
    "    the loss value for each prediction is a scalar value\n",
    "    generally, lower loss is better\n",
    "    L denotes loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1.2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the formal definition of the diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training using (stochastic) gradient descent</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the goal is to minimize the loss function by adjusting the Parameters\n",
    "        - just like finding roots for an equation\n",
    "        - gradient descent (GD) is used to find roots for an equation\n",
    "        - GD is computationally expensive and takes a long amount of time\n",
    "        - thus stochastic gradient descent is used (SGD)\n",
    "        - subset of points are used \n",
    "            - PURE SGD is when one point is used\n",
    "            - minibatch SGD is when a subset of points is used and there's more than one point\n",
    "        - pure SGD is rarely used due to very slow convergence due to noisy updates\n",
    "        - multiple variants of SGD explored later\n",
    "        - iteravely updating parameters is called backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Observation and Target Encoding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- algorithnms do not take text as input and can only perform calculations on numbers\n",
    "    - thus we turn characters, words, sentences, paragraphs, etc. into a numerical representation\n",
    "    - 1.3.png\n",
    "    - One-Hot Representation:\n",
    "        - Indexes words in the universal set\n",
    "        - use a 1 if the word is present\n",
    "        - use a 0 if the word is not present\n",
    "        - Consider the following lines\n",
    "            Time flies like an arrow.\n",
    "            Fruit flies like a banana.\n",
    "        - universal set (vocab size) would yield {time, fruit, flies, like, a, an, arrow, banana}\n",
    "        - binary encoding for \"like a banana\" would be [0, 0, 0, 1, 1, 0, 0, 1]\n",
    "        - NOTE: two different meanings of flies are compressed to the same in one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Term - Frequency (TF)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sum of one hot representations of its consituent\n",
    "- Term-Frequency of a word is denoted by TF(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:53.326663Z",
     "start_time": "2019-09-25T05:03:47.844119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29c3c5fe908>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = [\n",
    "    'Time flies flies like an arrow.',\n",
    "    'Fruit flies like a banana.'\n",
    "]\n",
    "\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(\n",
    "    one_hot,\n",
    "    annot=True,\n",
    "    cbar=False,\n",
    "    xticklabels=[\n",
    "        'an',\n",
    "        'arrow',\n",
    "        'banana',\n",
    "        'flies',\n",
    "        'fruit',\n",
    "        'like',\n",
    "        'time'\n",
    "    ],\n",
    "    yticklabels=[\n",
    "        'Sentence 1',\n",
    "        'Sentence 2'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Term Frequency Inverse Document Frequency (TF-IDF)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When words are repeated a lot in a document they provide less unique information\n",
    "- thus the IDF part of TF-IDF penalizes the weight of words that appear more often\n",
    "- IDF(w) = log(N/n_w)\n",
    "    where n_w is the number of docs with word w and N is total # of docs\n",
    "- NOTE: more common words across docs will be closer to value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:53.465251Z",
     "start_time": "2019-09-25T05:03:53.328628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29c3e822208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "sns.heatmap(\n",
    "    tfidf,\n",
    "    annot=True,\n",
    "    cbar=False,\n",
    "    xticklabels=[\n",
    "        'an',\n",
    "        'arrow',\n",
    "        'banana',\n",
    "        'flies',\n",
    "        'fruit',\n",
    "        'like',\n",
    "        'time'\n",
    "    ],\n",
    "    yticklabels=[\n",
    "        'Sentence 1',\n",
    "        'Sentence 2'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it is rare to see this used since it's better to learn a representation of words\n",
    "- since that way we lose less information (e.g. words with multiple meanings, how words belong to similar categores etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Target Encoding</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target variable depends on problem that is being solved\n",
    "- e.g. machine translation, summarization, question answering: target is text\n",
    "- in categorical, sometimes there are too many categories\n",
    "    - e.g. language modeling problem (predict next word) too many words thus problem revisited later\n",
    "- Numerical predictions\n",
    "    - e.g. predict a restaurant rating based on a review, grading an essay\n",
    "    - strategies include: binning numbers (0 - 18, 19 - 35, etc.)\n",
    "    - treat as ordinal classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computational Graphs</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/1.6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computational Graphs are a type of data structure\n",
    "- abstraction model of mathematical expressions\n",
    "- e.g. TensorFlow PyTorch Theano\n",
    "- Computational graphs keep track of extra information for automatic differentiation to obtain gradients of parameters during training\n",
    "- inference is simply expression evaluation (forward flow on a computation graph)\n",
    "- Drawn as a directed acyclic graph (DAG)\n",
    "    - nodes are operations\n",
    "    - inputs are incoming edges\n",
    "    - output is outgoing edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PyTorch Basics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch: optimized tensor manipulation library for deep learning\n",
    "- open source, community driven deep learning framework\n",
    "- uses tape-based automatic differentiation (unlike theano, caffe, and tensorflow)\n",
    "    - allows user to define and execute computational graphs dynamically\n",
    "    - helpful for debugging & consturcting sophisticated models with less effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dynamic vs Static Computational Graphs</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Static Frameworks: Theano, Caffe, Tensorflow\n",
    "    - require computational graph to be, declared and compiled before execution\n",
    "    - provides more efficient implementations (useful for production and mobility)\n",
    "    - not really suitable for research and development\n",
    "- Dynamic Frameworks: Chainer, DyNet, Pytorch\n",
    "    - more flexible\n",
    "    - imperative style of development (does not require compilation before execution\n",
    "    - useful for NLP modelling tasks since each input could result in different graph structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Goals:</h3>\n",
    "<ul>\n",
    "    <li>Create Tensors</li>\n",
    "    <li>Operations with Tensors</li>\n",
    "    <li>Indexing, slicing, and joining tensors</li>\n",
    "    <li>Computing gradients with tensors</li>\n",
    "    <li>Using CUDA tensors with GPUS</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T18:45:54.926420Z",
     "start_time": "2019-08-19T18:45:54.916465Z"
    }
   },
   "source": [
    "<h3>Installing PyTorch</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytorch.org has a menu which allows users to select their system setup and returns the command that needs to be run\n",
    "- e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/cmd.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.823647Z",
     "start_time": "2019-09-25T05:03:53.468229Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mathematical object holding some multi - dimensional data\n",
    "- tensor of order (rank) zero is just a number (scalar)\n",
    "- tensor of order (rank) one is an array of numbers (vector)\n",
    "- tensor of order (rank) two is a matrix\n",
    "- n dimensional array of scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating Tensors</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- describe that returns\n",
    "    - tensor type\n",
    "    - dimension\n",
    "    - contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.828982Z",
     "start_time": "2019-09-25T05:03:54.824988Z"
    }
   },
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor with random contents but specified dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.851913Z",
     "start_time": "2019-09-25T05:03:54.830969Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[7.2874e-03, 9.3607e-43, 7.2874e-03],\n",
      "        [9.3607e-43, 3.7096e-03, 9.3607e-43]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor with random values from\n",
    "    - uniform distribution\n",
    "    - normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.866873Z",
     "start_time": "2019-09-25T05:03:54.853908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.6917, 0.7362, 0.4888],\n",
      "        [0.1274, 0.9771, 0.5449]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.880835Z",
     "start_time": "2019-09-25T05:03:54.869866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-0.1667,  0.4128,  1.4983],\n",
      "        [ 0.3506, -0.3451,  1.0583]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.randn(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor filled with\n",
    "    - zeros\n",
    "    - ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.894800Z",
     "start_time": "2019-09-25T05:03:54.884824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.zeros(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.908762Z",
     "start_time": "2019-09-25T05:03:54.897792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.ones(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor filled with any scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.923721Z",
     "start_time": "2019-09-25T05:03:54.911762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[9., 9., 9.],\n",
      "        [9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "x.fill_(9)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Any PyTorch method with underscore (e.g. fill_()) refers to an in - place operation, it modifies content in place without creating a new object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor from python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.936686Z",
     "start_time": "2019-09-25T05:03:54.924719Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create tensor from numpy array\n",
    "    - we can also make numpy arrays with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.954638Z",
     "start_time": "2019-09-25T05:03:54.938682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.3837, 0.0963, 0.0373],\n",
      "        [0.9140, 0.3486, 0.4744]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "npy = np.random.rand(2, 3)\n",
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tensor Types and Sizes</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- default type when using torch.Tensor(): torch.FloatTensor\n",
    "- tensor types (float, long, double, etc.) can be converted 2 ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- during initialization (2 ways to initialize)\n",
    "    - calling type specific object constructor\n",
    "        - e.g. torch.FloatTensor() or torch.LongTensor()\n",
    "    - or passing a keyword arguement to torch.Tensor() with the torch data type\n",
    "        - e.g. torch.Tensor(..., dtype=torch.int64)\n",
    "-  type casting methods\n",
    "    - e.g. torch.Tensor(...).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.969611Z",
     "start_time": "2019-09-25T05:03:54.956634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.FloatTensor([[1, 2, 3],\n",
    "                        [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.980570Z",
     "start_time": "2019-09-25T05:03:54.971593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.FloatTensor([[1, 2, 3],\n",
    "                        [4, 5, 6]]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:54.991541Z",
     "start_time": "2019-09-25T05:03:54.982565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.tensor([[1, 2, 3],[4, 5, 6]], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.003509Z",
     "start_time": "2019-09-25T05:03:54.993537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.tensor([[1, 2, 3],[4, 5, 6]], dtype=torch.int64).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tensor Operations</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensors come with two methods of operation:\n",
    "    - using operator symbols: +, -, *, /\n",
    "    - using operator methods: .add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.008496Z",
     "start_time": "2019-09-25T05:03:55.005502Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.021459Z",
     "start_time": "2019-09-25T05:03:55.010491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.8169,  0.4170,  2.1024],\n",
      "        [-0.4176,  0.8028, -0.2204]])\n"
     ]
    }
   ],
   "source": [
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.033427Z",
     "start_time": "2019-09-25T05:03:55.022457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-3.6339,  0.8340,  4.2049],\n",
      "        [-0.8352,  1.6057, -0.4408]])\n"
     ]
    }
   ],
   "source": [
    "describe(x + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.043401Z",
     "start_time": "2019-09-25T05:03:55.034424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-3.6339,  0.8340,  4.2049],\n",
      "        [-0.8352,  1.6057, -0.4408]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.add(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other methods\n",
    "    - torch.arange(int)\n",
    "        - creates a rank one tensor that starts at the 0th position and increments\n",
    "    - \"tensor\".view(int, int)\n",
    "        - reshapes a tensor to the new dimensions\n",
    "    - torch.sum(\"tensor\", dim=0)\n",
    "        - sums elements in the same column\n",
    "    - torch.sum(\"tensor\", dim=1)\n",
    "        - sums elements in the same row\n",
    "    - torch.transpose(\"tensor\", 0, 1)\n",
    "        - transposes the tensor based on the given dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.053376Z",
     "start_time": "2019-09-25T05:03:55.045397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([6])\n",
      "Values: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.063349Z",
     "start_time": "2019-09-25T05:03:55.055371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(2, 3)\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.078330Z",
     "start_time": "2019-09-25T05:03:55.068355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(y, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.088307Z",
     "start_time": "2019-09-25T05:03:55.081301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(y, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.104240Z",
     "start_time": "2019-09-25T05:03:55.090275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(y, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Indexing, and Slicing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.113234Z",
     "start_time": "2019-09-25T05:03:55.106233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.123189Z",
     "start_time": "2019-09-25T05:03:55.114212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0, 1]])\n"
     ]
    }
   ],
   "source": [
    "describe(x[:1, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.135155Z",
     "start_time": "2019-09-25T05:03:55.125181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "describe(x[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.151113Z",
     "start_time": "2019-09-25T05:03:55.137150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "describe(torch.index_select(x, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.160089Z",
     "start_time": "2019-09-25T05:03:55.152109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 0])\n",
    "describe(torch.index_select(x, dim=0, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.174078Z",
     "start_time": "2019-09-25T05:03:55.162111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([0, 4])\n"
     ]
    }
   ],
   "source": [
    "row_indices = torch.arange(2).long()\n",
    "col_indices = torch.LongTensor([0, 1])\n",
    "describe(x[row_indices, col_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Indices must be of type torch.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Concatenation/Joining</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.183027Z",
     "start_time": "2019-09-25T05:03:55.176072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.196020Z",
     "start_time": "2019-09-25T05:03:55.185022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x, x], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.205968Z",
     "start_time": "2019-09-25T05:03:55.198014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 6])\n",
      "Values: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x, x],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.215940Z",
     "start_time": "2019-09-25T05:03:55.207960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.stack([x, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T20:26:26.540957Z",
     "start_time": "2019-08-24T20:26:26.535975Z"
    }
   },
   "source": [
    "<h4>Multiplication, inverse, and trace</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.226910Z",
     "start_time": "2019-09-25T05:03:55.216938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x1 = x.float()\n",
    "describe(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.238879Z",
     "start_time": "2019-09-25T05:03:55.228905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.ones(3, 2)\n",
    "x2[:, 1] += 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.258845Z",
     "start_time": "2019-09-25T05:03:55.240875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n"
     ]
    }
   ],
   "source": [
    "describe(torch.mm(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensors and Computational Graphs</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensors encapsulate (OOP paradigm which means to bundle) data, algebraic operations, indexing reshaping etc.\n",
    "- when boolean flag 'requires_grad' is set to True the tensor can then keep track of gradient and gradient function\n",
    "    - needed for the gradient based learning\n",
    "- PyTorch logic:\n",
    "    - tracks values of forward pass\n",
    "    - at computation end scalar is used to compute a backward pass \n",
    "        - initiated by 'backward()' method on tensor resulting from evaluation on loss function\n",
    "    - computes gradient value for each tensor object that participated in forward pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.270810Z",
     "start_time": "2019-09-25T05:03:55.259821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.283758Z",
     "start_time": "2019-09-25T05:03:55.272787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.436379Z",
     "start_time": "2019-09-25T05:03:55.284757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients\n",
    "General:\n",
    "- a value that represents the slope of output with respect to input\n",
    "Computational Graph specific\n",
    "- gradients exist for each parameter of model\n",
    "    - can be thought as contribution to final error\n",
    "- '.grad' returns the gradient of a node in the computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CUDA Tensors</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all tensors have been allocated on CPU\n",
    "- when doing linear algebra operations, we should utilize the GPU if we have one\n",
    "- to use GPU, tensor's must be GPU allocated\n",
    "- CUDA API gives access to GPU\n",
    "- created by NVIDIA for NVIDIA GPUs\n",
    "- Torch offers CUDA tensor objects which are indistinguishable from regular CPU tensors except for how they are allocated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in Torch it's easy to create CUDA tensors, transfer from CPU to GPU while maintaining type\n",
    "- preferred way to write code is to be device agnostic, so it works whether or not it's GPU or CPU\n",
    "- example\n",
    "    - check if GPU is available\n",
    "    - if so retrieve the GPU as a device\n",
    "    - then all future tensors are moved to that device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.445325Z",
     "start_time": "2019-09-25T05:03:55.437346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:55.456330Z",
     "start_time": "2019-09-25T05:03:55.447322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# preferred method: dvice agnostic tenor instantiation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.853954Z",
     "start_time": "2019-09-25T05:03:55.458292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.cuda.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.4922, 0.5687, 0.2511],\n",
      "        [0.5676, 0.5831, 0.4662],\n",
      "        [0.9803, 0.4133, 0.0200]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3).to(device)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- operations between objects must be between objects on the same device\n",
    "- moving data in and out of GPU is expensive\n",
    "- typical procedure:\n",
    "    - parallelizable computations on GPU then transfer final result to CPU\n",
    "- if you have several CUDA-visible devices (multiple GPUs) use CUDA_VISIBLE_DEVICES environment variable when exectuing program\n",
    "    - 'CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py'\n",
    "- parallelism and multi-GPU training not covered but essential to scale and train large models\n",
    "    - refer to Torch Docs and discussion forums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercises</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.879919Z",
     "start_time": "2019-09-25T05:03:58.855947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3, 3])\n",
      "Values: \n",
      "tensor([[[0.4270, 0.5472, 0.2485],\n",
      "         [0.8538, 0.4119, 0.2488],\n",
      "         [0.2655, 0.2981, 0.2311]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3, 3])\n",
      "Values: \n",
      "tensor([[[0.4270, 0.5472, 0.2485],\n",
      "         [0.8538, 0.4119, 0.2488],\n",
      "         [0.2655, 0.2981, 0.2311]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3, 3])\n",
      "Values: \n",
      "tensor([[[0.4270, 0.5472, 0.2485],\n",
      "         [0.8538, 0.4119, 0.2488],\n",
      "         [0.2655, 0.2981, 0.2311]]])\n"
     ]
    }
   ],
   "source": [
    "one = torch.rand(3, 3)\n",
    "describe(one.unsqueeze(0))\n",
    "describe(torch.unsqueeze(one, 0))\n",
    "describe(one[None,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.900829Z",
     "start_time": "2019-09-25T05:03:58.881877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.4270, 0.5472, 0.2485],\n",
      "        [0.8538, 0.4119, 0.2488],\n",
      "        [0.2655, 0.2981, 0.2311]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.4270, 0.5472, 0.2485],\n",
      "        [0.8538, 0.4119, 0.2488],\n",
      "        [0.2655, 0.2981, 0.2311]])\n"
     ]
    }
   ],
   "source": [
    "describe(one.unsqueeze(0).squeeze(0))\n",
    "describe(torch.squeeze(torch.unsqueeze(one, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.915789Z",
     "start_time": "2019-09-25T05:03:58.902822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([5, 3])\n",
      "Values: \n",
      "tensor([[6.1781, 6.7948, 3.0571],\n",
      "        [6.1753, 6.4312, 3.4104],\n",
      "        [4.2131, 6.5430, 3.0883],\n",
      "        [3.9093, 5.2050, 3.7284],\n",
      "        [6.1543, 6.9596, 4.2145]])\n"
     ]
    }
   ],
   "source": [
    "describe(4 * torch.rand(5, 3) + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.926758Z",
     "start_time": "2019-09-25T05:03:58.917782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3456, -0.6162,  1.2007],\n",
       "        [ 0.2832, -0.5967, -0.9135],\n",
       "        [-0.1894,  0.1335, -1.5971]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 3)\n",
    "torch.rand(3, 3).normal_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.936730Z",
     "start_time": "2019-09-25T05:03:58.928752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([1,1,1,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.948701Z",
     "start_time": "2019-09-25T05:03:58.938726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1121],\n",
       "         [0.2343],\n",
       "         [0.5677]],\n",
       "\n",
       "        [[0.1121],\n",
       "         [0.2343],\n",
       "         [0.5677]],\n",
       "\n",
       "        [[0.1121],\n",
       "         [0.2343],\n",
       "         [0.5677]],\n",
       "\n",
       "        [[0.1121],\n",
       "         [0.2343],\n",
       "         [0.5677]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 1)\n",
    "x.expand(4, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:58.982607Z",
     "start_time": "2019-09-25T05:03:58.950694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 5])\n",
      "Values: \n",
      "tensor([[[3.4373e-01, 9.1124e-01, 3.0427e-02, 9.3244e-01, 1.3437e-01],\n",
      "         [1.0506e-01, 5.7745e-04, 4.6654e-01, 8.3675e-01, 8.9411e-01],\n",
      "         [3.4347e-02, 6.7840e-01, 7.1323e-01, 4.7030e-01, 4.5278e-01],\n",
      "         [7.1229e-01, 2.4006e-01, 9.9932e-02, 4.9990e-01, 6.4776e-01]],\n",
      "\n",
      "        [[9.4904e-01, 5.3112e-01, 3.5220e-01, 6.9380e-02, 1.1460e-01],\n",
      "         [1.6702e-01, 3.6145e-01, 5.0095e-01, 7.7478e-01, 8.7523e-01],\n",
      "         [7.9318e-01, 1.7031e-01, 2.7884e-01, 3.2972e-01, 5.3384e-01],\n",
      "         [3.0402e-01, 9.2304e-01, 4.8896e-01, 6.0123e-01, 6.3155e-01]],\n",
      "\n",
      "        [[3.2810e-01, 8.9415e-01, 3.1727e-02, 8.6620e-01, 6.9496e-01],\n",
      "         [3.7954e-01, 3.5068e-01, 2.6746e-01, 2.5060e-01, 9.6907e-01],\n",
      "         [3.4475e-01, 6.5019e-01, 7.6002e-01, 5.1548e-01, 4.2115e-01],\n",
      "         [8.6959e-01, 3.0305e-01, 2.9528e-01, 1.6845e-01, 2.0882e-02]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 5, 4])\n",
      "Values: \n",
      "tensor([[[0.2329, 0.7780, 0.3832, 0.2944],\n",
      "         [0.8927, 0.8554, 0.8493, 0.1766],\n",
      "         [0.3929, 0.1895, 0.5668, 0.2309],\n",
      "         [0.9109, 0.8138, 0.3293, 0.2683],\n",
      "         [0.5935, 0.5221, 0.4245, 0.4336]],\n",
      "\n",
      "        [[0.9315, 0.9318, 0.5705, 0.9242],\n",
      "         [0.8531, 0.6842, 0.2095, 0.4158],\n",
      "         [0.7238, 0.2356, 0.4863, 0.9587],\n",
      "         [0.5219, 0.1687, 0.7552, 0.7003],\n",
      "         [0.3040, 0.6353, 0.2901, 0.9133]],\n",
      "\n",
      "        [[0.5683, 0.8369, 0.1006, 0.4070],\n",
      "         [0.4481, 0.6041, 0.2833, 0.6218],\n",
      "         [0.5452, 0.4854, 0.4573, 0.1612],\n",
      "         [0.1724, 0.9955, 0.3524, 0.4784],\n",
      "         [0.6588, 0.1176, 0.2483, 0.9700]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[1.8346, 1.8816, 1.2870, 0.5775],\n",
      "         [1.5012, 1.3184, 0.9603, 0.7509],\n",
      "         [1.5910, 1.3613, 1.3407, 0.6171],\n",
      "         [1.2593, 1.5234, 0.9731, 0.6901]],\n",
      "\n",
      "        [[1.6630, 1.4152, 0.9096, 1.5888],\n",
      "         [1.4969, 1.2077, 1.2536, 2.1269],\n",
      "         [1.4203, 1.3161, 1.0276, 1.7896],\n",
      "         [1.9302, 1.5327, 1.2418, 2.1314]],\n",
      "\n",
      "        [[1.2116, 1.7741, 0.7786, 1.7831],\n",
      "         [1.2003, 1.0227, 0.5887, 1.4755],\n",
      "         [1.2679, 1.6129, 0.8526, 1.3222],\n",
      "         [0.8338, 1.2243, 0.3729, 0.6908]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(3, 5, 4)\n",
    "describe(a)\n",
    "describe(b)\n",
    "describe(torch.bmm(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:03:59.015520Z",
     "start_time": "2019-09-25T05:03:58.984602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 5])\n",
      "Values: \n",
      "tensor([[[0.4697, 0.8817, 0.8698, 0.8761, 0.4229],\n",
      "         [0.2700, 0.4112, 0.5515, 0.8236, 0.1751],\n",
      "         [0.1212, 0.4974, 0.9459, 0.1721, 0.8866],\n",
      "         [0.8884, 0.6462, 0.9219, 0.8386, 0.5173]],\n",
      "\n",
      "        [[0.9776, 0.9906, 0.9792, 0.8572, 0.4516],\n",
      "         [0.0498, 0.5790, 0.1815, 0.0837, 0.4870],\n",
      "         [0.2214, 0.2690, 0.0195, 0.5827, 0.7176],\n",
      "         [0.8437, 0.9128, 0.0573, 0.2995, 0.0990]],\n",
      "\n",
      "        [[0.0064, 0.5996, 0.9895, 0.8955, 0.0116],\n",
      "         [0.0515, 0.1882, 0.4647, 0.1592, 0.3514],\n",
      "         [0.3225, 0.4492, 0.1004, 0.7742, 0.1637],\n",
      "         [0.5131, 0.9332, 0.8274, 0.9776, 0.2662]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([5, 4])\n",
      "Values: \n",
      "tensor([[0.0660, 0.5198, 0.3591, 0.9431],\n",
      "        [0.8886, 0.7805, 0.5453, 0.2796],\n",
      "        [0.4010, 0.5946, 0.0192, 0.8797],\n",
      "        [0.4363, 0.8162, 0.5119, 0.2672],\n",
      "        [0.1379, 0.5124, 0.0374, 0.0953]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[1.6037, 2.3812, 1.1304, 1.7290],\n",
      "         [0.9879, 1.5512, 0.7599, 1.0915],\n",
      "         [1.0266, 1.6085, 0.4541, 1.2160],\n",
      "         [1.4397, 2.4637, 1.1377, 2.1028]],\n",
      "\n",
      "        [[1.7736, 2.7945, 1.3657, 2.3323],\n",
      "         [0.6943, 0.9036, 0.3981, 0.4373],\n",
      "         [0.6146, 1.1798, 0.5516, 0.5252],\n",
      "         [1.0341, 1.4802, 0.9589, 1.1908]],\n",
      "\n",
      "        [[1.3223, 1.7965, 0.8071, 1.2846],\n",
      "         [0.4749, 0.7600, 0.2247, 0.5860],\n",
      "         [0.8210, 1.2936, 0.7651, 0.7404],\n",
      "         [1.6580, 2.4212, 1.2193, 1.7592]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(5, 4)\n",
    "describe(a)\n",
    "describe(b)\n",
    "describe(torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chapter 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - NLP and CL (computational linguistics) deal with human language.\n",
    "     - NLP aim: develop methods for solving practical language problems\n",
    "         - e.g. information extraction automatic speech recognition, machine translation, sentiment analysis, question answering, summarization etc.\n",
    "     - CL aim: understand properties of human language\n",
    "         - understand language, produce language, learn language, language relationships\n",
    "- CL and NLP work together and become their own fields (phonology, morphology, syntax, semantics, and pragmatics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Corpora, Tokens and Types</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- text dataset is called corpus or corpora (plural)\n",
    "    - contains raw text (usually ASCII or UTF-8 text encoding) and metadata\n",
    "- raw text is a sequence of characters(bytes)\n",
    "    - characers can be grouped into units called tokens\n",
    "        - in english tokens are words and numeric sequences separated by white space characters or punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- metadata: any auxilary piece of info associated with text\n",
    "    - e.g. identifiers, labels, timestamps etc.\n",
    "- text coupled with metadata is an instance/data point\n",
    "- corpus/dataset is collection of instances\n",
    "- tokenization: breaking text in tokens\n",
    "    - there are turtles (3 tokens: \"there\", \"are\", \"turtles\")\n",
    "- Agglutinative languages like Turkish need more than just splitting by punctuation and whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenizing tweets involves preserving hashtags and @handles, and segmenting smileys/emojis and URLS as a single unit.\n",
    "- NLTK and spaCy are two common packages for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:00.700859Z",
     "start_time": "2019-09-25T05:03:59.017514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', ',', 'do', \"n't\", 'slap', 'the', 'green', 'witch']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"Mary, don't slap the green witch\"\n",
    "print([str(token) for token in nlp(text.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:01.456974Z",
     "start_time": "2019-09-25T05:04:00.702855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snow', 'white', 'and', 'the', 'seven', 'degrees', 'makeamoviecold', '@midnight', ':-)']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet = u\"Snow White and the Seven Degrees \\nMakeAMovieCold@midnight :-)\"\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(tweet.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Types are unique tokens in a corpus.\n",
    "- set of all types is its vocabulary/lexicon\n",
    "- words are either content words or stopwords\n",
    "- stopwords such as articles and prepositions serve as grammar and are fillers for content words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Engineering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process of understanding linguistics of language\n",
    "- levaraging the above to solve the NLP problems\n",
    "- minimize feature engineering for convenience and portability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Unigrams, Bigrams, Trigrams, ..., N-grams</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N - grams are fixed length (n) consecutive token sequences occurring in the text.\n",
    "    - Bi - gram is two tokens, uni - gram is one token etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:01.464971Z",
     "start_time": "2019-09-25T05:04:01.458968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
     ]
    }
   ],
   "source": [
    "def n_grams(text, n):\n",
    "    '''\n",
    "    takes tokens or text, returns a list of n-grams\n",
    "    '''\n",
    "    return [text[i:i+n] for i in range (len(text) - n + 1)]\n",
    "\n",
    "cleaned = ['mary', ',', \"n't\", 'slap', 'green', 'witch', '.']\n",
    "print(n_grams(cleaned, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- character n - grams can be useful when subwords carry useful info\n",
    "    - e.g. suffix \"ol\" in \"methanol\" indicates alcohol\n",
    "- same code would work but just treat each letter as a token instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lemmas and Stems</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lemma: root form of words\n",
    "    - e.g. fly: flow, flew, flies ,flown, flowing\n",
    "- token reduction to lemma keeps dimensionality of vector representation low: lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:01.682390Z",
     "start_time": "2019-09-25T05:04:01.466946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he --> -PRON-\n",
      "was --> be\n",
      "running --> run\n",
      "late --> late\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"he was running late\")\n",
    "for token in doc:\n",
    "    print('{} --> {}'.format(token, token.lemma_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stemming is budget lemmatization\n",
    "- involves handcrafted rules to strip word endings into stems\n",
    "    - e.g. Porter and Snowball stemmers (google it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Categorizing Sentences and Documents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- earliest applications of NLP\n",
    "- TF & TF-IDF immediately useful for classifying & categorizing large text\n",
    "- supverised document classification problmes:\n",
    "    - assiging topic labels\n",
    "    - predicting sentiment of reviews\n",
    "    - filtering spam emails\n",
    "    - language identification\n",
    "    - email triaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Categorizing Words: POS Tagging</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- labeling individual words/tokens\n",
    "- Part of speeching tagging is a example of token categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:01.882835Z",
     "start_time": "2019-09-25T05:04:01.684368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary - PROPN\n",
      "slapped - VERB\n",
      "the - DET\n",
      "green - ADJ\n",
      "witch - NOUN\n",
      ". - PUNCT\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Mary slapped the green witch.\")\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Categorizing Spans: Chunking and Named Entity Recognition</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- often labeling span of text needed (contiguous multitoken boundary)\n",
    "    - e.g. Noun Phraes vs Verb Phrases\n",
    "    - \"Mary slapped the green witch.\"\n",
    "        - mary -> Noun Phrase\n",
    "        - slapped -> verb phrase\n",
    "- also called chunking/shallow parsing\n",
    "    - derive higher order units composed of nouns, verbs, adjectives etc.\n",
    "- possible to wite regex over POS tags to approximate shallow parsing if you cannot train your own shallow parsing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.069336Z",
     "start_time": "2019-09-25T05:04:01.884829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary - NP\n",
      "the green witch - NP\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Mary slapped the green witch.\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('{} - {}'.format(chunk, chunk.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Named entity also extremely useful for people, locations, organizations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Structure of Sentences</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shallow parsing identifies phrasal units\n",
    "- parsing: identifying relationships between phrasal units\n",
    "- parse trees indicate hierarchy of different grammatical units\n",
    "    - e.g. constituent parse, dependency parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Word Senses and Semantics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Senses: different meanings of a word\n",
    "- WordNet: long running lexical resource project (princeton)\n",
    "    - catalogs senses of A LOT of english language\n",
    "    - lexical relationships between words as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chapter 3: Foundational Components of Neural Netowrks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- introduction\n",
    "    - activation functions\n",
    "    - loss functions\n",
    "    - optimizers\n",
    "    - supervised training setup\n",
    "- Perceptron: one-unit neural network\n",
    "    - building block to more complex neural networks\n",
    "    - every architecture or network can be standalone or used with other complex networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Perceptron: The Simplest Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modeled after biological neuron\n",
    "- \"signals\" flow from input and output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/3.1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weights and bias learned from data\n",
    "- activation function handpicked depending on creator's intuition of network & target ouput\n",
    "- mathematical expression: y = f(wx+b)\n",
    "    - x typically has multiple inputs thus x & w are vectors and wx represent a dot product\n",
    "- activation functions (f) are typically non - linear functions.\n",
    "- perceptron: composition of a linear and nonlinear function\n",
    "- wx + b also known as affine transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- perceptron implementation in PyTorch\n",
    "    - arbitrary number of inputs\n",
    "    - applies affine transform\n",
    "    - applies activation function\n",
    "    - produces output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.077316Z",
     "start_time": "2019-09-25T05:04:02.071362Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    '''\n",
    "    A perceptron is one linear layer\n",
    "    '''\n",
    "    def __init__(self, input_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim (int): size of the input features\n",
    "        '''\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "        \n",
    "        def forward(self, x_in):\n",
    "            '''\n",
    "            Forward pass of the perceptron\n",
    "            Args:\n",
    "                x_in (torch.Tensor): an input data tensor x_in.shape should be (batch, num_features)\n",
    "            Returns:\n",
    "                the resulting tensor. tensor.shape should be (batch,).\n",
    "            '''\n",
    "            return torch.sigmoid(self.fc1(x_in)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear class in torch.nn module does bookkeeping for weights & biases and applies affine transform\n",
    "- sigmoid activation function used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Activation Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nonlinearities introduced to neural network\n",
    "- caputre complex relationships\n",
    "- explained in \"Diving Deep into Supervised Training\" and \"Multilayer Perceptron\" why they're required\n",
    "- common activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sigmoid</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- maps real number to value from 0 to 1\n",
    "- mathematical sigmoid: f(x) = (1 + e^-x)^-1\n",
    "- easy to see sigmoid is smooth & differentiable\n",
    "- torch code: torch.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.225915Z",
     "start_time": "2019-09-25T05:04:02.079309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.arange(-5., 5., 0.1)\n",
    "y = torch.sigmoid(x)\n",
    "plt.plot(x.numpy(), y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- saturates\n",
    "- leads to\n",
    "    - gradient becoming zero (vanishing gradient problem)\n",
    "    - diverging to overflowing floating point value (exploding gradient problem)\n",
    "- rare to see use in neural nets except at output where squashing allows one to interpret output as probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tanh</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cosmetically different variant of sigmoid\n",
    "- mathematical expression: tanh(x) = (e^x-e^-x)/(e^x+e^-x)\n",
    "- tanh is linear transform of sigmoid function\n",
    "- also \"squashing\" function\n",
    "- maps from real numbers to -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.368535Z",
     "start_time": "2019-09-25T05:04:02.227913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(-5., 5., .1)\n",
    "y = torch.tanh(x)\n",
    "plt.plot(x.numpy(), y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ReLU</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rectified Linear Unit\n",
    "- arguably most import activation function\n",
    "- mathematical expression: f(x) = max(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.554051Z",
     "start_time": "2019-09-25T05:04:02.370531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "x = torch.arange(-5.,5.,.1)\n",
    "y = relu(x)\n",
    "plt.plot(x.numpy(), y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fixes the vanishing gradient problem but but trade off is the \"dying ReLU\"\n",
    "    - certain output become zero and never revive\n",
    "- to mitigate, leaky ReLU and Parametrix ReLU (PReLU) have been proposed\n",
    "    - leaked coefficient is learned\n",
    "- f(x) = max(x, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.711619Z",
     "start_time": "2019-09-25T05:04:02.556033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prelu = torch.nn.PReLU(num_parameters=1)\n",
    "x = torch.arange(-5., 5., .1)\n",
    "y = prelu(x)\n",
    "plt.plot(x.numpy(), y.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Softmax</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- squashes unit output from 0 to 1\n",
    "- also divides each output by sum of all output\n",
    "- provides descrete probability distribution over k classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/3.6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- resulting distribution sum up to one\n",
    "- useful for classification output interpretation\n",
    "- paired with probabilistic training objective (e.x. categorical cross entropy covered later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.737549Z",
     "start_time": "2019-09-25T05:04:02.712628Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3])\n",
      "Values: \n",
      "tensor([[ 0.9467, -0.5813, -0.0360]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3])\n",
      "Values: \n",
      "tensor([[0.6284, 0.1363, 0.2352]])\n",
      "\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1])\n",
      "Values: \n",
      "tensor([1.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "softmax = nn.Softmax(dim=1)\n",
    "x_input = torch.randn(1, 3)\n",
    "y_output = softmax(x_input)\n",
    "describe(x_input)\n",
    "print(\"\")\n",
    "describe(y_output)\n",
    "print(\"\")\n",
    "describe(torch.sum(y_output, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loss Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- guides training algo to pick parameters suing data\n",
    "- provides score using prediction and truth\n",
    "- higher score equals worse prediction\n",
    "- commonly used below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean Squared Error Loss</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- regression problems where target and output are continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MSE.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- average of squared differences\n",
    "- other common regression loss functions\n",
    "    - mean absolute error, root mean squared error\n",
    "- all involve computing a real value difference between target and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:04:02.751545Z",
     "start_time": "2019-09-25T05:04:02.739545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0400, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch.randn(3, 5)\n",
    "loss = mse_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Categorical Cross - Entropy Loss</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- typical usage: multiclass classification where output is class membership probabilities\n",
    "- target is vector of n elements\n",
    "    - represents true multinomial distribution over all classes\n",
    "    - vector is one hot if only one true class\n",
    "- output is also size n\n",
    "    - models guess of distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/CCEL.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- method to compute distribution difference\n",
    "- float specific considerations for computing loss\n",
    "    - limit of float size\n",
    "    - large negative/postive in softmax is amplified\n",
    "    - network output is the layer before softmax\n",
    "    - log in cross_entropy inverses exponential\n",
    "- allows for softmax at final output to be used with cross-entropy to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:26:06.579171Z",
     "start_time": "2019-09-25T05:26:06.562217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0668, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "outputs = torch.randn(3, 5, requires_grad=True)\n",
    "targets = torch. tensor([1, 0 ,3], dtype=torch.int64)\n",
    "loss = ce_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Binary Cross-Entropy Loss</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- between two classes\n",
    "- BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T05:40:20.429067Z",
     "start_time": "2019-09-25T05:40:20.412139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0773],\n",
      "        [0.7049],\n",
      "        [0.5438],\n",
      "        [0.5049]], grad_fn=<SigmoidBackward>)\n",
      "tensor(1.2730, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "probabilities = sigmoid(torch.randn(4, 1, requires_grad=True))\n",
    "targets = torch.tensor([1, 0, 1, 0], dtype=torch.float32).view(4, 1)\n",
    "loss = bce_loss(probabilities, targets)\n",
    "print(probabilities)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Diving Deep into Supervised Training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- supervised learning:\n",
    "    - map observations to targets given labeled examples\n",
    "- use model predictions & loss function for gradient-based optimization on model parameters\n",
    "- supervised learning requires:\n",
    "    - model\n",
    "        - computes prediction from observations\n",
    "    - loss function\n",
    "        - measures error of predictions to target\n",
    "    - training data\n",
    "        - observeration, target pairs\n",
    "    - optimization algorithm\n",
    "        - adjusts model's parameters to minimize the loss\n",
    "- classic toy problem:\n",
    "    - 2d points into two classes\n",
    "    - basically finding a boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Constructing Toy Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- common practice:\n",
    "    - create synthetic data with understood properties to understand algorithms\n",
    "- sample points from two parts of x - y plane creating easy to learn situation for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/3.2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Choosing a model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- perceptron:\n",
    "    - allows any input size\n",
    "        - input size generally determined by task and data\n",
    "    - input size is 2\n",
    "        - constructed data is in 2d plane\n",
    "    - numeric indices to classes: 0 & 1\n",
    "        - doesn't matter if circle is 0 or 1 and star is 0 or 1 as long as consistency kept\n",
    "    - perceptron activation function is sigmoid\n",
    "        - perceptron output is probability of datapoint being class 1\n",
    "        - P(y = 1|x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Converting the probabilities to discrete classes</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- impose decision boundary sigma\n",
    "- if P(Y=1|x) > sigma x is 1 else x is 0\n",
    "- typically boundary set to 0.5 but this hyperparameter is tuned to achieve desired precision in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Choosing loss function</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since situation is model ouput is probability cross entropy based loss is most appropriate\n",
    "- binary classification -> BCE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Choosing an optimizer</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer updates wieghts of model using error signal\n",
    "- learning rate: hyperparameter that controls update behaviour of optimizer\n",
    "    - large learning rate\n",
    "        - causes bigger changes to parameter\n",
    "        - affects convergence\n",
    "    - small learning rate\n",
    "        - very little progress during training\n",
    "    - use default before tuning\n",
    "        - unless research paper says otherwise\n",
    "- Stochastic gradient descent is classic algorithm\n",
    "    - difficult optimization problems causes SGD to have convergence issues\n",
    "- preffered alternative:\n",
    "    - adaptive optimizers such as Adagrad/Adam\n",
    "        - Adam default learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-26T04:31:22.489459Z",
     "start_time": "2019-09-26T04:31:22.477439Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "input_dim = 2\n",
    "lr=0.001\n",
    "\n",
    "perceptron = Perceptron(input_dim=input_dim)\n",
    "bce_loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(params=perceptron.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Putting it Together: Gradient-Based Supervised Learning</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forward pass for loss to see how far off current model is\n",
    "- gradient of loss ecomes signal for magnitude parameters should change\n",
    "- gradient for each parameter represents instantaneous rate of change in loss value given the parameter\n",
    "    - parameter's contribution to loss funciton\n",
    "- each parameter on own hill and wants to go down\n",
    "- iterative updating of each parameter with gradient of loss with respect to parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient - stepping algo\n",
    "    - bookkeeping info such as gradients in model object cleared using zero_grad()\n",
    "    - computes output with input data (x_data -> y_pred)\n",
    "    - loss computed using prediction and target (loss(y_pred, y_target))\n",
    "    - pytorch loss object (criterion) has function backward()\n",
    "        - iteratively propagates loss backward through computational graph and notifies each parameter of its gradient\n",
    "    - optimizer instructs parameters how to update values knowing gradient with step() function\n",
    "- training dataset partitioned into batches\n",
    "- each iteration of gradient step performed on one data batch\n",
    "- hyperparameter named batch_size\n",
    "- training dataset is fixed ths larger batch size decreases number of batches\n",
    "- certain number of batches is an epoch (typically number of batches to go through entire dataset)\n",
    "- models are trained certain number of epochs\n",
    "- methods for determining how many epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 3-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T03:08:56.281605Z",
     "start_time": "2019-10-01T03:08:56.134001Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-385cce327596>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# each epoch is complete pass over train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Step 0: Get Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_toy_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# each epoch is complete pass over train data\n",
    "for epoch_i in range(n_epochs):\n",
    "    \n",
    "    # Step 0: Get Data\n",
    "    x_data, y_data = get_toy_data(batch_size)\n",
    "    \n",
    "    # Step 1: Clear the gradients\n",
    "    perceptron.zero_grad()\n",
    "    \n",
    "    # Step 2: Compute the forward pass of the model\n",
    "    y_pred = perceptron(x_data, apply_sigmoid=True)\n",
    "    \n",
    "    # Step 3: Compute the loss value that we wish to optimize\n",
    "    loss = bce_loss(y_pred, y_target)\n",
    "    \n",
    "    # step 4 Propagate the loss signal backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 5: Trigger the optimizer to perform one update\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Auxiliary Training Concepts</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Core idea of supervised gradient-based learning:\n",
    "    - define model\n",
    "    - compute outputs\n",
    "    - use loss to compute gradients\n",
    "    - apply optimizer to update model parameters with gradient\n",
    "- following is important auxiliary concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correctly Measuring Model Performance: Evaluation Metrics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- most important non core concept\n",
    "- objective performance measure on data model has never seen\n",
    "- most common is accuracy:\n",
    "    - fraction of predictions correct on data not seen during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correctly Measuring Model Performance: Dataset Split</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- goal is to always generalize well to true distribution of data\n",
    "- there exists distribution of data globally assuming we can see infinite amount of data\n",
    "    - true/unseen distribution\n",
    "- finite distribution that approximates incomplete picture of true distribution\n",
    "- better generalization:\n",
    "    - reduces error on samples in training AND samples from unseen distribution\n",
    "- careful of model adapting to idiosyncrasies (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- standard practices: \n",
    "    - split dataset into three randomly sampled partitions\n",
    "        - training, validation, test\n",
    "        - simpler method\n",
    "        - single computation\n",
    "        - make sure distribution of classes remain same between each three split\n",
    "            - aggregate dataset by class label then random split each set separated by class label\n",
    "        - common split ratio\n",
    "            - 70% training\n",
    "            - 15% validation\n",
    "            - 15% testing\n",
    "    - k-fold cross validation\n",
    "        - split entire dataset into k equally sized 'folds'\n",
    "        - 1 fold reserved for evaluation and the ramining used for training\n",
    "        - iteratively repeated with different fold as evaluation\n",
    "        - obtain k accuracy values\n",
    "        - final accuracy is average with standard deviation\n",
    "        - computationally expensive but necessary for smaller datasets\n",
    "            - helps avoid when test data has harder/easir examples\n",
    "- predefined training, validation and test split may exiust: common in benchmarking tasks\n",
    "    - training data: update model parameters\n",
    "    - validation data: measuring model performance at end of every epoch\n",
    "    - test data: after all modeling choices explored and final results needed\n",
    "        - super important to avoid bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Knowing when to stop training</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simplest approach: fixed epoch training\n",
    "    - arbitrary and unnecessary\n",
    "- correctly measuring model performance helps determine when to stop training\n",
    "- common method is to use a heuristic called 'early stopping'\n",
    "    - keeps track of performance on validation dataset, epoch to epoch\n",
    "    - performance does not improve -> training terminates\n",
    "    - patience: number of epochs it waits before termination\n",
    "    - model convergence: model stops improving on some dataset\n",
    "        - rarely wait for model to completely converge\n",
    "            - b/c time consuming & can lead to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding right Hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameter\n",
    "    - takes real values adjusted by optimizer with respect to fixed subset of training data called minibatch\n",
    "- hyperparameter\n",
    "    - model setting that affects\n",
    "        - number of parameters\n",
    "        - values taken by parameters\n",
    "    - e.g. loss function, optimizer, learning rates for optimizer, layer size, patience for early stopping, regularization decisions\n",
    "    - decisions have large effect on model convergence and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regularization</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- comes from numerical optimization theory\n",
    "- ml algorithms optimize loss function to find most likely values of parameters\n",
    "- there could be multiple solutions\n",
    "- consider the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/3.3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- occam's razor: simpler explanation is more likely\n",
    "- smoothness constraint is called L2 Regularization\n",
    "- controlled by weight_decay parameter in optimizer\n",
    "    - larger wegiht_decay value -> more likely optimizer will select smoother explanation\n",
    "- L1 regularization also popular\n",
    "    - encourages sparser solutions\n",
    "    - model parameter values closer to zero\n",
    "- chapter 4 looks at dropout\n",
    "    - structural regularization technique\n",
    "- active research area\n",
    "- pytorch flexible for implementing custom regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Example: Classifying Sentiment of Restaurant Reviews</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- classify whether restaurant reviews on Yelp are positive or negative using a perceptron and supervised training\n",
    "- Dataset\n",
    "    - Yelp dataset\n",
    "        - pairs reviews with sentiment label\n",
    "            - positive or negative\n",
    "- three assisting classes\n",
    "    - Vocabulary\n",
    "        - token to integer mappings\n",
    "        - also maps class labels to integers\n",
    "    - Vectorizer\n",
    "        - encapsulates vocabularies\n",
    "        - responsible for ingesting string data\n",
    "        - e.g. review's text -> numerical vectors\n",
    "    - DataLoader\n",
    "        - groups and collates individual vectorized data into minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The Yelp Review Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2015 Yelp Contest: predict rating of restaurant given a review\n",
    "    - Zhang, Zhao, and Lecun (2015) simpliefied dataset\n",
    "        - converted 1 star and 2 star to negative\n",
    "        - 3 and 4 star are positive\n",
    "    - 560 000 training samples / 38 000 testing samples\n",
    "- use simplified yelp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset difference, we select only 10% of training samples as full dataset\n",
    "    - training - testing loop fast so we can experiment more quickly\n",
    "    - model has lower accuracy\n",
    "        - not major issue since we can retrain entire datset using knowledge gained from smaller subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from smaller subset, tri partition data: training, validation, testing\n",
    "- if model decisions are based on held out portion model will be biased towards held out data\n",
    "    - training partition derives model parameters\n",
    "    - validation partition selects among hyperparameters\n",
    "    - testing is only for final model evaluation\n",
    "- Example 3-12: splits dataset\n",
    "- Notes\n",
    "    - seed set to a static number\n",
    "    - aggregate by class label to gurantee class distribution remains same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
